{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2026f6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import _pickle as cPickle\n",
    "from scipy.io import loadmat\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer ,TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "254f1800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>liked</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>India is developing countries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Da Vinci Code book is just awesome.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>this was the first clive cussler i've ever rea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   liked                                               text\n",
       "0      1                      India is developing countries\n",
       "1      1            The Da Vinci Code book is just awesome.\n",
       "2      1  this was the first clive cussler i've ever rea..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Training.txt\",sep=\"\\t\", names=['liked','text'],encoding=\"utf-8\");\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd9f2207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6931\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "146a1287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liked</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2975</td>\n",
       "      <td>559</td>\n",
       "      <td>I hate Harry Potter.</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3956</td>\n",
       "      <td>744</td>\n",
       "      <td>I love Harry Potter.</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text                                  \n",
       "      count unique                   top freq\n",
       "liked                                        \n",
       "0      2975    559  I hate Harry Potter.   85\n",
       "1      3956    744  I love Harry Potter.  167"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('liked').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6321ac3",
   "metadata": {},
   "source": [
    "## Data Prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8d99936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens(review):\n",
    "    return TextBlob(review).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bb1eeb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   [India, is, developing, countries]\n",
       "1      [The, Da, Vinci, Code, book, is, just, awesome]\n",
       "2    [this, was, the, first, clive, cussler, i, 've...\n",
       "3             [i, liked, the, Da, Vinci, Code, a, lot]\n",
       "4             [i, liked, the, Da, Vinci, Code, a, lot]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().text.apply(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5295794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ready', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('a', 'DT'),\n",
       " ('good', 'JJ'),\n",
       " ('movie', 'NN')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"ready was not a good movie\").tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bb58b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     [india, is, developing, country]\n",
       "1      [the, da, vinci, code, book, is, just, awesome]\n",
       "2    [this, wa, the, first, clive, cussler, i, 've,...\n",
       "3             [i, liked, the, da, vinci, code, a, lot]\n",
       "4             [i, liked, the, da, vinci, code, a, lot]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_lemmas(review):\n",
    "    wordss = TextBlob(review.lower()).words\n",
    "    # for each word, take its \"base form\" = lemma \n",
    "    return [word.lemma for word in wordss]\n",
    "\n",
    "df.text.head().apply(to_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc362591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'octopus'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "lmtzr.lemmatize('octopi')\n",
    "#nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8a3e05",
   "metadata": {},
   "source": [
    "## Converting text data into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "324d9ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2114\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bow_transformer = CountVectorizer(analyzer=to_lemmas).fit(df['text'])\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce31904e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i liked the Da Vinci Code a lot.\n"
     ]
    }
   ],
   "source": [
    "review1=df['text'][3]\n",
    "print(review1)\n",
    "#to check 3rd document/review in collection/database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5217c0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 8 stored elements and shape (1, 2114)>\n",
      "  Coords\tValues\n",
      "  (0, 42)\t1\n",
      "  (0, 369)\t1\n",
      "  (0, 458)\t1\n",
      "  (0, 950)\t1\n",
      "  (0, 1123)\t1\n",
      "  (0, 1152)\t1\n",
      "  (0, 1838)\t1\n",
      "  (0, 1977)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 2114)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow=bow_transformer.transform([review1])\n",
    "print(bow)\n",
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6399b0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code-other\n"
     ]
    }
   ],
   "source": [
    "print(bow_transformer.get_feature_names_out()[372])\n",
    "#to check 372nd word in collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9dbe5826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (6931, 2114)\n",
      "number of non-zeros: 71297\n",
      "sparsity: 7129700.00%\n"
     ]
    }
   ],
   "source": [
    "review_bow = bow_transformer.transform(df['text'])\n",
    "print( 'sparse matrix shape:', review_bow.shape)\n",
    "print('number of non-zeros:', review_bow.nnz) #learn this\n",
    "print( 'sparsity: %.2f%%' % (100.0 * review_bow.nnz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c64e102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6931, 2114)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer =TfidfTransformer().fit(review_bow)\n",
    "review_tfidf = tfidf_transformer.transform(review_bow)\n",
    "review_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b43578f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5544 1387 5544 1387\n"
     ]
    }
   ],
   "source": [
    "text_train, text_test, liked_train, liked_test = train_test_split(df['text'], df['liked'], test_size=0.2)\n",
    "print(len(text_train), len(text_test), len(text_train) , len(text_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4c8d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_svm = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=to_lemmas)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', SVC()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37909125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline parameters to automatically explore and tune\n",
    "param_svm = [\n",
    "  {'classifier__C': [1, 10, 100, 1000], 'classifier__kernel': ['linear']},\n",
    "  {'classifier__C': [1, 10, 100, 1000], 'classifier__gamma': [0.001, 0.0001], 'classifier__kernel': ['rbf']},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964adc29",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1243a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svm = GridSearchCV(\n",
    "    pipeline_svm, #object used to fit the data\n",
    "    param_grid=param_svm, \n",
    "    refit=True,  # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,  # number of cores to use for parallelization; -1 for \"all cores\" i.e. to run on all CPUs\n",
    "    scoring='accuracy',#optimizing parameter\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1dfb4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.55 s\n",
      "Wall time: 17.5 s\n",
      "{'mean_fit_time': array([1.49073825, 1.60808182, 1.43570733, 1.55739946, 4.04829497,\n",
      "       4.3012362 , 3.28285489, 3.82417688, 1.80940185, 3.13761058,\n",
      "       1.50387177, 1.54784689]),\n",
      " 'mean_score_time': array([0.37128472, 0.39284968, 0.36423535, 0.40360222, 0.882657  ,\n",
      "       1.02232218, 0.75175548, 0.87516303, 0.4649416 , 0.67466707,\n",
      "       0.37400813, 0.34074454]),\n",
      " 'mean_test_score': array([0.99242431, 0.99224413, 0.99224413, 0.99224413, 0.57016599,\n",
      "       0.57016599, 0.97384722, 0.57016599, 0.99007985, 0.97384722,\n",
      "       0.99188312, 0.99026019]),\n",
      " 'param_classifier__C': masked_array(data=[1, 10, 100, 1000, 1, 1, 10, 10, 100, 100, 1000, 1000],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value=999999),\n",
      " 'param_classifier__gamma': masked_array(data=[--, --, --, --, 0.001, 0.0001, 0.001, 0.0001, 0.001,\n",
      "                   0.0001, 0.001, 0.0001],\n",
      "             mask=[ True,  True,  True,  True, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value=1e+20),\n",
      " 'param_classifier__kernel': masked_array(data=['linear', 'linear', 'linear', 'linear', 'rbf', 'rbf',\n",
      "                   'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value=np.str_('?'),\n",
      "            dtype=object),\n",
      " 'params': [{'classifier__C': 1, 'classifier__kernel': 'linear'},\n",
      "            {'classifier__C': 10, 'classifier__kernel': 'linear'},\n",
      "            {'classifier__C': 100, 'classifier__kernel': 'linear'},\n",
      "            {'classifier__C': 1000, 'classifier__kernel': 'linear'},\n",
      "            {'classifier__C': 1,\n",
      "             'classifier__gamma': 0.001,\n",
      "             'classifier__kernel': 'rbf'},\n",
      "            {'classifier__C': 1,\n",
      "             'classifier__gamma': 0.0001,\n",
      "             'classifier__kernel': 'rbf'},\n",
      "            {'classifier__C': 10,\n",
      "             'classifier__gamma': 0.001,\n",
      "             'classifier__kernel': 'rbf'},\n",
      "            {'classifier__C': 10,\n",
      "             'classifier__gamma': 0.0001,\n",
      "             'classifier__kernel': 'rbf'},\n",
      "            {'classifier__C': 100,\n",
      "             'classifier__gamma': 0.001,\n",
      "             'classifier__kernel': 'rbf'},\n",
      "            {'classifier__C': 100,\n",
      "             'classifier__gamma': 0.0001,\n",
      "             'classifier__kernel': 'rbf'},\n",
      "            {'classifier__C': 1000,\n",
      "             'classifier__gamma': 0.001,\n",
      "             'classifier__kernel': 'rbf'},\n",
      "            {'classifier__C': 1000,\n",
      "             'classifier__gamma': 0.0001,\n",
      "             'classifier__kernel': 'rbf'}],\n",
      " 'rank_test_score': array([ 1,  2,  2,  2, 10, 10,  8, 10,  7,  8,  5,  6], dtype=int32),\n",
      " 'split0_test_score': array([0.99368801, 0.99368801, 0.99368801, 0.99368801, 0.57078449,\n",
      "       0.57078449, 0.97565374, 0.57078449, 0.98917944, 0.97565374,\n",
      "       0.99368801, 0.98917944]),\n",
      " 'split1_test_score': array([0.99368801, 0.99549143, 0.99549143, 0.99549143, 0.56988278,\n",
      "       0.56988278, 0.97024346, 0.56988278, 0.99368801, 0.97024346,\n",
      "       0.99368801, 0.99368801]),\n",
      " 'split2_test_score': array([0.99368801, 0.99278629, 0.99278629, 0.99278629, 0.56988278,\n",
      "       0.56988278, 0.97745717, 0.56988278, 0.99188458, 0.97745717,\n",
      "       0.99368801, 0.99188458]),\n",
      " 'split3_test_score': array([0.98827773, 0.98557259, 0.98557259, 0.98557259, 0.56988278,\n",
      "       0.56988278, 0.96302976, 0.56988278, 0.98286745, 0.96302976,\n",
      "       0.9864743 , 0.98376916]),\n",
      " 'split4_test_score': array([0.99277978, 0.99368231, 0.99368231, 0.99368231, 0.57039711,\n",
      "       0.57039711, 0.98285199, 0.57039711, 0.99277978, 0.98285199,\n",
      "       0.99187726, 0.99277978]),\n",
      " 'std_fit_time': array([0.19159373, 0.2171476 , 0.10765328, 0.24745996, 0.54406766,\n",
      "       0.28742109, 0.28998848, 0.28467223, 0.20113679, 0.35986385,\n",
      "       0.16967674, 0.09551031]),\n",
      " 'std_score_time': array([0.06434576, 0.08023363, 0.05683801, 0.0684328 , 0.03267217,\n",
      "       0.16587809, 0.11655356, 0.1262794 , 0.05752225, 0.01609628,\n",
      "       0.04351591, 0.03222311]),\n",
      " 'std_test_score': array([0.00210292, 0.00344968, 0.00344968, 0.00344968, 0.00036786,\n",
      "       0.00036786, 0.00674367, 0.00036786, 0.00390884, 0.00674367,\n",
      "       0.00279386, 0.00357878])}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "%time classifier = grid_svm.fit(text_train, liked_train) # find the best combination from param_svm\n",
    "pprint(classifier.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8d5db14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       592\n",
      "           1       0.99      0.99      0.99       795\n",
      "\n",
      "    accuracy                           0.99      1387\n",
      "   macro avg       0.99      0.99      0.99      1387\n",
      "weighted avg       0.99      0.99      0.99      1387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(liked_test, classifier.predict(text_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73d2d832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict([\"the vinci code is awesome\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fcbbc555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict([\"the vinci code is bad\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "833c6ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.32465246735834974)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gaussKernel(x1, x2, sigma):\n",
    "    ss=np.power(sigma,2)\n",
    "    norm= (x1-x2).T.dot(x1-x2)\n",
    "    return np.exp(-norm/(2*ss))\n",
    "x1 = np.array([1, 2, 1])\n",
    "x2 = np.array([0, 4, -1])\n",
    "sigma = 2\n",
    "gaussKernel(x1,x2,sigma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
